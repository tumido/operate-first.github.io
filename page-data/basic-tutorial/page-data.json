{"componentChunkName":"component---src-templates-doc-js","path":"/basic-tutorial/","result":{"data":{"site":{"siteMetadata":{"title":"Operate First"}},"markdownRemark":{"id":"c3d585f6-7564-5936-9223-9d4ef30d1717","excerpt":"Pre-requisites This Tutorial requires a basic installation of Open Data Hub with Spark and JupyterHub as detailed in the quick installation. The quick…","html":"<h3>Pre-requisites</h3>\n<p>This Tutorial requires a basic installation of Open Data Hub with Spark and JupyterHub as detailed in the <a href=\"/operate-first.github.io_example-pr-deployment/quick-installation\">quick installation</a>. The quick installation steps are also available as a <a class=\"external-link\" href=\"https://www.youtube.com/watch?v=-T6ypF7LoKk&t=2s\" target=\"_blank\"><i class=\"fas fa-external-link-alt\"></i>tutorial video</a> on the OpenShift youtube channel.</p>\n<p>All screenshots and instructions are from OpenShift 4.4. For the purposes of this tutorial, we used <a href=\"https://try.openshift.com/\">try.openshift.com</a> on AWS. Tutorials have also been tested on <a href=\"https://code-ready.github.io/crc/\">Code Ready Containers</a> with 16GB of RAM.</p>\n<p>The <a href=\"./basic_tutorial_notebook.ipynb\">source</a> for the following notebook is available in GitLab with comments for easy viewing.</p>\n<h3>Exploring JupyterHub and Spark</h3>\n<p>JupyterHub and Spark are installed by default with Open Data Hub. You can create Jupyter Notebooks and connect to Spark. This is a simple <code class=\"language-text\">hello world</code> example.</p>\n<ol class=\"pf-c-list\">\n<li>Find the route to JupyterHub. Within your Open Data Hub Project click on <code class=\"language-text\">Networking</code> -> <code class=\"language-text\">Routes</code>\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/operate-first.github.io_example-pr-deployment/static/a8f8f4675aa8814bf2d1c9b15013bf0e/c2d13/routes.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 51.35135135135135%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAABa0lEQVQoz62QS0/CQBSF+x9coMhbEh4WxGhMJIIYlxIfLNxoVJDgK+6NiX/QH+BWBRdGSbQtLXQePc6U2mCiRo03+TrTmXPPnFwlk0xCzWaRSOcQXaoiVFzzCQvi4myUqVIVCUHM00bLW0hUaogvbyJaWoeSVguYCEWw22jh5tHA7YuNjk7R9uiMYlA8GMP1XXOvEZ+2RqGo+VmMT0bQaLZwfWfhSSf4dTlMflyU9HQegWAYdWHYtTieewSvfQbNHGBgEziOA0oZbELAxZ5QKv6p28wYExobnAsNG2qUjDCUCXf26jCFTjbL0nuaK5ZFKYFlme6+Txi6BkFvwGGLc90yIFvkwxKlWF5BRp3B8em5G5ox7iaRr3NPJOGcyy4wkca0uQuRWs7dhL7hRm0bpcoqLi6vvHkMLz4d1Q/GqcwvLGIqlcXRyZnn53wJvrnzE6ayOYwFgtivH34w/GspucIcguEYDhrNfzF8A+IZqoE2n2VUAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Routes\"\n        title=\"Routes\"\n        src=\"/operate-first.github.io_example-pr-deployment/static/a8f8f4675aa8814bf2d1c9b15013bf0e/fcda8/routes.png\"\n        srcset=\"/operate-first.github.io_example-pr-deployment/static/a8f8f4675aa8814bf2d1c9b15013bf0e/12f09/routes.png 148w,\n/operate-first.github.io_example-pr-deployment/static/a8f8f4675aa8814bf2d1c9b15013bf0e/e4a3f/routes.png 295w,\n/operate-first.github.io_example-pr-deployment/static/a8f8f4675aa8814bf2d1c9b15013bf0e/fcda8/routes.png 590w,\n/operate-first.github.io_example-pr-deployment/static/a8f8f4675aa8814bf2d1c9b15013bf0e/efc66/routes.png 885w,\n/operate-first.github.io_example-pr-deployment/static/a8f8f4675aa8814bf2d1c9b15013bf0e/c83ae/routes.png 1180w,\n/operate-first.github.io_example-pr-deployment/static/a8f8f4675aa8814bf2d1c9b15013bf0e/c2d13/routes.png 2560w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></li>\n<li>For the route named <code class=\"language-text\">jupyterhub</code>, click on the location to bring up JupyterHub (typically <code class=\"language-text\">https://jupyterhub-project.apps.your-cluster.your-domain.com</code>).</li>\n<li>Sign in using your OpenShift credentials.</li>\n<li>Spawn a new server with spark functionality. (e.g. <code class=\"language-text\">s2i-spark-minimal-notebook:py36-spark2.4.5-hadoop2.7.3</code>)\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/operate-first.github.io_example-pr-deployment/static/f3f87d0598b9ba87a05468769c845a0b/c2d13/new-notebook.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 51.35135135135135%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAAAzklEQVQoz52SXQ6DIBCEvf9V2reepL9HoE/GFK2LoEwdKgZNrbabTEAYxm8JmdQVjDFwzqJt2yDnHLquA8tai6qqUJZl8MX96E3P0Jthoeq6RlEUQQwTkXBorTLvPeZiaa2hlAoj/0xi7nGM80+aEKaBbJN0JG2aZmw3Bs79I+G3wDzPIX1gShDpfg4kEe+O95a2+nfgsyeTPpRf7Rjm3woeerElcHgu6gw57mCuB5jbIM5Pe7j7ZfB32wm96+nkAW/0VFxzsq3lNHitljwv0eET+cT+kJEAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"New Notebook\"\n        title=\"New Notebook\"\n        src=\"/operate-first.github.io_example-pr-deployment/static/f3f87d0598b9ba87a05468769c845a0b/fcda8/new-notebook.png\"\n        srcset=\"/operate-first.github.io_example-pr-deployment/static/f3f87d0598b9ba87a05468769c845a0b/12f09/new-notebook.png 148w,\n/operate-first.github.io_example-pr-deployment/static/f3f87d0598b9ba87a05468769c845a0b/e4a3f/new-notebook.png 295w,\n/operate-first.github.io_example-pr-deployment/static/f3f87d0598b9ba87a05468769c845a0b/fcda8/new-notebook.png 590w,\n/operate-first.github.io_example-pr-deployment/static/f3f87d0598b9ba87a05468769c845a0b/efc66/new-notebook.png 885w,\n/operate-first.github.io_example-pr-deployment/static/f3f87d0598b9ba87a05468769c845a0b/c83ae/new-notebook.png 1180w,\n/operate-first.github.io_example-pr-deployment/static/f3f87d0598b9ba87a05468769c845a0b/c2d13/new-notebook.png 2560w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></li>\n<li>Create a new Python 3 notebook</li>\n<li>\n<p>Copy the following code to test a basic spark connection.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> pyspark<span class=\"token punctuation\">.</span>sql <span class=\"token keyword\">import</span> SparkSession<span class=\"token punctuation\">,</span> SQLContext\n<span class=\"token keyword\">import</span> os\n<span class=\"token keyword\">import</span> socket\n\n<span class=\"token comment\"># create a spark session</span>\nspark_cluster_url <span class=\"token operator\">=</span> <span class=\"token string-interpolation\"><span class=\"token string\">f\"spark://</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>os<span class=\"token punctuation\">.</span>environ<span class=\"token punctuation\">[</span><span class=\"token string\">'SPARK_CLUSTER'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">:7077\"</span></span>\nspark <span class=\"token operator\">=</span> SparkSession<span class=\"token punctuation\">.</span>builder<span class=\"token punctuation\">.</span>master<span class=\"token punctuation\">(</span>spark_cluster_url<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>getOrCreate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># test your spark connection</span>\nspark<span class=\"token punctuation\">.</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> numPartitions<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>rdd<span class=\"token punctuation\">.</span><span class=\"token builtin\">map</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">lambda</span> x<span class=\"token punctuation\">:</span> socket<span class=\"token punctuation\">.</span>gethostname<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>distinct<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>collect<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n</li>\n<li>\n<p>Run the notebook. If successful, you should see the output similar to the following:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">[&#39;spark-cluster-kube-3aadmin-w-gx7rm&#39;, &#39;spark-cluster-kube-3aadmin-w-xvl55&#39;]</code></pre></div>\n</li>\n</ol>\n<h3>Object Storage</h3>\n<p>Let’s add on to the notebook from the previous section and access data on an Object Store (such as Ceph or AWS S3) using the S3 API. For instructions on installing Ceph, refer to the Advanced Installation <a href=\"%7B%7Bsite.baseurl%7D%7D/docs/administration/advanced-installation/object-storage.html\">documentation</a>.</p>\n<ol class=\"pf-c-list\">\n<li>Click on the <code class=\"language-text\">+</code> button and insert a new cell of type <code class=\"language-text\">Code</code>.</li>\n<li>\n<p>To access S3 directly, we’ll use the <code class=\"language-text\">boto3</code> library. We’ll download a sample data file and then upload it to our S3 storage. In the new cell paste the following code, and edit the <code class=\"language-text\">s3_</code> variables with your own credentials.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Edit this section using your own credentials</span>\ns3_region <span class=\"token operator\">=</span> <span class=\"token string\">'region-1'</span> <span class=\"token comment\"># fill in for AWS, blank for Ceph</span>\ns3_endpoint_url <span class=\"token operator\">=</span> <span class=\"token string\">'https://s3.storage.server'</span>\ns3_access_key_id <span class=\"token operator\">=</span> <span class=\"token string\">'AccessKeyId-ChangeMe'</span>\ns3_secret_access_key <span class=\"token operator\">=</span> <span class=\"token string\">'SecretAccessKey-ChangeMe'</span>\ns3_bucket <span class=\"token operator\">=</span> <span class=\"token string\">'MyBucket'</span>\n\n<span class=\"token comment\"># for easy download</span>\n!pip install wget\n\n<span class=\"token keyword\">import</span> wget\n<span class=\"token keyword\">import</span> boto3\n\n<span class=\"token comment\"># configure boto S3 connection</span>\ns3 <span class=\"token operator\">=</span> boto3<span class=\"token punctuation\">.</span>client<span class=\"token punctuation\">(</span><span class=\"token string\">'s3'</span><span class=\"token punctuation\">,</span>\n                  s3_region<span class=\"token punctuation\">,</span>\n                  endpoint_url <span class=\"token operator\">=</span> s3_endpoint_url<span class=\"token punctuation\">,</span>\n                  aws_access_key_id <span class=\"token operator\">=</span> s3_access_key_id<span class=\"token punctuation\">,</span>\n                  aws_secret_access_key <span class=\"token operator\">=</span> s3_secret_access_key<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># download the sample data file</span>\nurl <span class=\"token operator\">=</span> <span class=\"token string\">\"{{site.repo}}/opendatahub.io/raw/master/assets/files/tutorials/basic/sample_data.csv\"</span>\n<span class=\"token builtin\">file</span> <span class=\"token operator\">=</span> wget<span class=\"token punctuation\">.</span>download<span class=\"token punctuation\">(</span>url<span class=\"token operator\">=</span>url<span class=\"token punctuation\">,</span> out<span class=\"token operator\">=</span><span class=\"token string\">'sample_data.csv'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#upload the file to storage</span>\ns3<span class=\"token punctuation\">.</span>upload_file<span class=\"token punctuation\">(</span><span class=\"token builtin\">file</span><span class=\"token punctuation\">,</span> s3_bucket<span class=\"token punctuation\">,</span> <span class=\"token string\">\"sample_data.csv\"</span><span class=\"token punctuation\">)</span></code></pre></div>\n</li>\n<li>Run the cell. After it completes check your S3 bucket. You should see the <code class=\"language-text\">sample_data.csv</code>.</li>\n</ol>\n<h3>Spark + Object Storage</h3>\n<p>Now, let’s access that same data file from Spark so you can analyze the data.</p>\n<ol class=\"pf-c-list\">\n<li>Let’s read the data using Spark. First, click on the <code class=\"language-text\">+</code> button and insert a new cell of type <code class=\"language-text\">Code</code>.</li>\n<li>\n<p>Paste the following code to read the data using Spark and print the first few rows of data.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">hadoopConf <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>sparkContext<span class=\"token punctuation\">.</span>_jsc<span class=\"token punctuation\">.</span>hadoopConfiguration<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nhadoopConf<span class=\"token punctuation\">.</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"fs.s3a.endpoint\"</span><span class=\"token punctuation\">,</span> s3_endpoint_url<span class=\"token punctuation\">)</span>\nhadoopConf<span class=\"token punctuation\">.</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"fs.s3a.access.key\"</span><span class=\"token punctuation\">,</span> s3_access_key_id<span class=\"token punctuation\">)</span>\nhadoopConf<span class=\"token punctuation\">.</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"fs.s3a.secret.key\"</span><span class=\"token punctuation\">,</span> s3_secret_access_key<span class=\"token punctuation\">)</span>\nhadoopConf<span class=\"token punctuation\">.</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"fs.s3a.path.style.access\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"true\"</span><span class=\"token punctuation\">)</span>\nhadoopConf<span class=\"token punctuation\">.</span><span class=\"token builtin\">set</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"fs.s3a.connection.ssl.enabled\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"true\"</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># false if not https</span>\n\ndata <span class=\"token operator\">=</span> spark<span class=\"token punctuation\">.</span>read<span class=\"token punctuation\">.</span>csv<span class=\"token punctuation\">(</span><span class=\"token string\">'s3a://'</span> <span class=\"token operator\">+</span> s3_bucket <span class=\"token operator\">+</span> <span class=\"token string\">'/sample_data.csv'</span><span class=\"token punctuation\">,</span>sep<span class=\"token operator\">=</span><span class=\"token string\">\",\"</span><span class=\"token punctuation\">,</span> header<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\ndf <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>toPandas<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ndf<span class=\"token punctuation\">.</span>head<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n</li>\n<li>Run the cell. The data from the <code class=\"language-text\">csv</code> file should be displayed as a Pandas data frame.</li>\n</ol>\n<p>That’s it! You have a working Jupyter notebook workspace with access to S3 storage and Spark.</p>","frontmatter":{"title":"Basic Tutorial","idx":1,"description":"Basic Tutorial"}}},"pageContext":{"slug":"/basic-tutorial/","previous":{"fields":{"slug":"/operate-first/"},"frontmatter":{"title":"Operate First"}},"next":null}},"staticQueryHashes":["3000541721","3177538707"]}